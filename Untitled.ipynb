{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c88fb81-98a6-4af3-9a9c-30c341efc141",
   "metadata": {},
   "source": [
    "# Used Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a2da1e5-b4a7-4381-923a-d1f64ae91989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Union, Tuple, Optional\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af8526-6922-4bd6-9d23-d6d2a6814fea",
   "metadata": {},
   "source": [
    "# Architecture of a single Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29746e0c-6652-4c2d-b738-0c9116bb8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, hidden_units, activation: Optional[str]=None, random_seed=None):\n",
    "        \"\"\"\n",
    "        Connected layer for a neural network.\n",
    "\n",
    "        :param num_neurons: The number of neurons in the layer\n",
    "        :param activation: The activation function to use (if any)\n",
    "        \"\"\"\n",
    "        if activation not in [None, 'relu', 'softmax']:\n",
    "            raise KeyError('wrong activation function')\n",
    "            \n",
    "        self.hidden_units = hidden_units\n",
    "        self.activation = activation\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.random_seed = random_seed if random_seed is not None else np.random.randint(0, 2**32 - 1)\n",
    "    \n",
    "    def _init_params(self, input_size: int, hidden_units: int):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases for the layer.\n",
    "\n",
    "        :param input_size: The number of inputs to the layer\n",
    "        :param num_neurons: The number of neurons in the layer\n",
    "        \"\"\"\n",
    "        \n",
    "        self.weights = np.random.RandomState(self.random_seed).randn(input_size, hidden_units) * np.sqrt(2. / input_size)\n",
    "        self.biases = np.zeros((1, hidden_units)) \n",
    "    \n",
    "    def _apply_activation(self, weighted_inputs: np.ndarray):\n",
    "        \"\"\"\n",
    "        Apply the activation function if any.\n",
    "        \"\"\"\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(weighted_inputs)\n",
    "        elif self.activation == 'softmax':\n",
    "            return self.softmax(weighted_inputs)\n",
    "        else:\n",
    "            return weighted_inputs  # just return input\n",
    "        \n",
    "    def _apply_activation_backward(self, weighted_inputs: np.ndarray, grad: np.ndarray):\n",
    "        \"\"\"\n",
    "        Apply the activation function if any.\n",
    "        \"\"\"\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu_backward(weighted_inputs, grad)\n",
    "        elif self.activation == 'softmax':\n",
    "            return self.softmax_backward(weighted_inputs, grad)\n",
    "        else:\n",
    "            return grad  # just return grad\n",
    "    \n",
    "    def forward_pass(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.inputs = inputs\n",
    "        if self.weights is None:\n",
    "            self._init_params(inputs.shape[-1], self.hidden_units)\n",
    "        \n",
    "        self.weighted_inputs = inputs @ self.weights + self.biases\n",
    "        return self._apply_activation(self.weighted_inputs)\n",
    "    \n",
    "    def backward_pass(self, next_layer_grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate the gradient of the loss function with respect to the input of the layer and parameters.\n",
    "\n",
    "        :param next_layer_grad: The gradient of the loss function with respect to the output of the next layer.\n",
    "        :return: The gradient of the loss function with respect to the input of the layer (dL/dx), weights and biases.\n",
    "        \"\"\"\n",
    "        da = self._apply_activation_backward(self.weighted_inputs, next_layer_grad)\n",
    "        db = np.sum(da, axis=0)\n",
    "        dw = self.inputs.T @ da\n",
    "        dx = da @ self.weights.T\n",
    "        return dx, dw, db\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x: np.ndarray, derivative=False) -> np.ndarray:\n",
    "        x = x - np.max(x)\n",
    "        s = np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "        return s\n",
    "        \n",
    "    @staticmethod\n",
    "    def softmax_backward(x: np.ndarray, grad: np.ndarray) -> np.ndarray:\n",
    "        x = x - np.max(x)\n",
    "        s = np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "        \n",
    "        diag = np.stack([\n",
    "            np.diag(s[i])\n",
    "            for i in range(len(s))\n",
    "        ], 0)\n",
    "        softmax_grad = diag - np.einsum('bi,bj->bij', s, s)\n",
    "        # grad: batch_size x class_num\n",
    "        # softmax_grad: batch_size x class_num x class_num\n",
    "        return np.einsum('bc,bcd->bd', grad, softmax_grad)\n",
    "                \n",
    "    @staticmethod           \n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    @staticmethod           \n",
    "    def relu_backward(x, grad):\n",
    "        relu_grad = (x >= 0).astype(x.dtype)\n",
    "        return relu_grad * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22949871-c777-48f1-8f41-94ebb02d5068",
   "metadata": {},
   "source": [
    "# Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "379b6fc1-e6d3-404d-a328-12d4a1054856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, learning_rate=0.01, momentum=0.9):\n",
    "        super().__init__(learning_rate)\n",
    "        self.momentum = momentum\n",
    "        self.velocity: List[Tuple[np.ndarray, np.ndarray]] = []\n",
    "\n",
    "    def update(self, layers, grads):\n",
    "        if not self.velocity:\n",
    "            self.velocity = [(np.zeros_like(layer.weights), np.zeros_like(layer.biases)) for layer in layers]\n",
    "\n",
    "        for (v_w, v_b), layer, (dw, db) in zip(self.velocity, layers, grads):\n",
    "            v_w *= self.momentum\n",
    "            v_w += self.learning_rate * dw\n",
    "            layer.weights -= v_w\n",
    "            \n",
    "            v_b *= self.momentum\n",
    "            v_b += self.learning_rate * db\n",
    "            layer.biases -= v_b\n",
    "            \n",
    "class AdaGrad(Optimizer):\n",
    "    def __init__(self, learning_rate=0.01, epsilon=1e-7):\n",
    "        super().__init__(learning_rate)\n",
    "        self.epsilon = epsilon\n",
    "        self.accumulated_grads: List[Tuple[np.ndarray, np.ndarray]] = []\n",
    "    \n",
    "    def update(self, layers: List[Layer], grads: List[Tuple[np.ndarray, np.ndarray]]):\n",
    "        if not self.accumulated_grads:\n",
    "            self.accumulated_grads = [(np.zeros_like(layer.weights), np.zeros_like(layer.biases)) for layer in layers]\n",
    "\n",
    "        for (h_w, h_b), layer, (dw, db) in zip(self.accumulated_grads, layers, grads):\n",
    "            h_w += dw * dw\n",
    "            layer.weights -= self.learning_rate * dw / (np.sqrt(h_w) + self.epsilon)\n",
    "            \n",
    "            h_b += db * db\n",
    "            layer.biases -= self.learning_rate * db / (np.sqrt(h_b) + self.epsilon)\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    \"\"\"\n",
    "    Adam optimizer implementation.\n",
    "    https://optimization.cbe.cornell.edu/index.php?title=Adam\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate: float = 0.001, beta1: float = 0.9, beta2: float = 0.999, epsilon: float = 1e-7):\n",
    "        \"\"\"\n",
    "        Initialize Adam optimizer.\n",
    "        \n",
    "        :param learning_rate: learning rate\n",
    "        :param beta1: The exponential decay rate for the first moment estimates\n",
    "        :param beta2: The exponential decay rate for the second-moment estimates\n",
    "        :param epsilon: small value to prevent division by zero\n",
    "        \"\"\"\n",
    "        super().__init__(learning_rate)\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m: List[Tuple[np.ndarray, np.ndarray]] = []\n",
    "        self.v: List[Tuple[np.ndarray, np.ndarray]] = []\n",
    "        self.t = 0\n",
    "        \n",
    "    def update(self, layers: List[Layer], grads: List[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
    "        \"\"\"\n",
    "        Perform the Adam update on parameters.\n",
    "\n",
    "        :param layers: list of layers with parameters to update\n",
    "        :param grads: list of gradients for each layer's parameters\n",
    "        \"\"\"\n",
    "        if not self.m:\n",
    "            self.m = [[np.zeros_like(layer.weights), np.zeros_like(layer.biases)] for layer in layers]\n",
    "            self.v = [[np.zeros_like(layer.weights), np.zeros_like(layer.biases)] for layer in layers]\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "        for (m, v), layer, (dw, db) in zip(zip(self.m, self.v), layers, grads):\n",
    "            m[0] *= self.beta1\n",
    "            m[0] += (1.0 - self.beta1) * dw\n",
    "            bias_corrected_first_moment = m[0] / (1.0 - self.beta1**self.t)\n",
    "            v[0] *= self.beta2\n",
    "            v[0] += (1.0 - self.beta2) * dw**2\n",
    "            bias_corrected_second_moment = v[0] / (1.0 - self.beta2**self.t)\n",
    "            \n",
    "            layer.weights -= self.learning_rate * bias_corrected_first_moment / (np.sqrt(bias_corrected_second_moment) + self.epsilon)\n",
    "\n",
    "            m[1] *= self.beta1\n",
    "            m[1] += (1.0 - self.beta1) * db\n",
    "            bias_corrected_first_moment = m[1] / (1.0 - self.beta1**self.t)\n",
    "            v[1] *= self.beta2\n",
    "            v[1] += (1.0 - self.beta2) * db**2\n",
    "            bias_corrected_second_moment = v[1] / (1.0 - self.beta2**self.t)\n",
    "            \n",
    "            layer.biases -= self.learning_rate * bias_corrected_first_moment / (np.sqrt(bias_corrected_second_moment) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd5894-6bbb-49fb-8dd2-e0df74242a55",
   "metadata": {},
   "source": [
    "# Artificial Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bba68bf-eb90-4460-84b1-c1bef7f744df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_epochs=100, batch_size=32, optimizer=SGD(learning_rate=0.01),\n",
    "                 activation='relu', hidden_sizes=[128], num_classes=4, verbose=False, random_seed=42):\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epochs = num_epochs\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        self.layers = [Layer(size, activation, random_seed=rng.randint(0, 2**32 - 1)) for size in hidden_sizes]\n",
    "        self.layers.append(Layer(num_classes, 'softmax', random_seed=rng.randint(0, 2**32 - 1)))\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    @staticmethod\n",
    "    def to_one_hot(y: np.ndarray, num_classes: int):\n",
    "        one_hot = np.zeros((y.shape[0], num_classes))\n",
    "        one_hot[range(y.shape[0]), y] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def categorical_cross_entropy(self, y_pred: np.ndarray, y_true: np.ndarray, derivative=False) -> Union[float, Tuple[np.ndarray, np.ndarray]]:\n",
    "        y_true = self.to_one_hot(y_true, self.num_classes)\n",
    "        \n",
    "        # Clip to prevent NaN's and Inf's to prevent log(0) or division by zero:\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if derivative:\n",
    "            return -y_true / y_pred\n",
    "            # return 2 * (y_pred - y_true)\n",
    "        else:\n",
    "            return -np.sum(y_true * np.log(y_pred), axis=-1)\n",
    "            # return ((y_true - y_pred) ** 2).sum(-1)\n",
    "    \n",
    "    def _create_mini_batches(self, X, y, batch_size, shuffle: bool, drop_last: bool):\n",
    "        \"\"\"\n",
    "        Creates mini-batches from the input data.\n",
    "\n",
    "        :param X: input features\n",
    "        :param y: targets\n",
    "        :param batch_size: size of the mini-batches\n",
    "        :yields: mini-batches\n",
    "        \"\"\"\n",
    "        if shuffle:\n",
    "            X, y = sklearn.utils.shuffle(X, y)\n",
    "        if drop_last:\n",
    "            n_minibatches = X.shape[0] // batch_size\n",
    "        else:\n",
    "            n_minibatches = (X.shape[0] + batch_size - 1) // batch_size\n",
    "        for i in range(n_minibatches):\n",
    "            yield X[i * batch_size : (i + 1) * batch_size], y[i * batch_size : (i + 1) * batch_size]\n",
    "    \n",
    "    def _forward(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Performs a forward pass throught the neural network.\n",
    "\n",
    "        :param X: input data\n",
    "        :return: the output of the last layer of the neural network, necessary to calculate backprop\n",
    "        \"\"\"\n",
    "        if not self.layers:\n",
    "            raise ValueError(\"No layers in the neural network.\")\n",
    "\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward_pass(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _backpropagation(self, y_pred: np.ndarray, y_true: np.ndarray):\n",
    "        \"\"\"\n",
    "        Executes the backpropagation algorithm.\n",
    "\n",
    "        The goal of backpropagation is to compute the gradient of the loss function with respect to the weights of the network,\n",
    "        which is done by propagating the gradient backwards through the network. The gradients are then used to update the weights and biases to minimize the loss\n",
    "        :param y_pred: network's output from the forward pass algorithm\n",
    "        :param y_true: true labels \n",
    "        \"\"\"\n",
    "        # Calculate the initial gradient as the derivative of the loss function\n",
    "        grads = []\n",
    "        dx = self.categorical_cross_entropy(y_pred, y_true, derivative=True)\n",
    "\n",
    "        for layer in self.layers[::-1]:\n",
    "            # Calculate the gradient at the current layer\n",
    "            dx, dw, db = layer.backward_pass(dx)\n",
    "            grads.append((dw, db))\n",
    "\n",
    "        grads = grads[::-1]\n",
    "        self.optimizer.update(self.layers, grads) # Update the weights and biases for all layers\n",
    "\n",
    "    def _run_single_epoch(self, X, y, optimize: bool):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for X_batch, y_batch in self._create_mini_batches(X, y, self.batch_size, shuffle=optimize, drop_last=optimize):\n",
    "            y_pred = self._forward(X_batch)\n",
    "\n",
    "            loss = self.categorical_cross_entropy(y_pred, y_batch)\n",
    "            total_loss += loss.sum()\n",
    "\n",
    "            correct = self.count_correct_predictions(y_batch, y_pred)\n",
    "            correct_predictions += correct\n",
    "\n",
    "            total_samples += len(X_batch)\n",
    "\n",
    "            if optimize:\n",
    "                self._backpropagation(y_pred, y_batch)\n",
    "\n",
    "        average_loss = total_loss / total_samples\n",
    "        average_accuracy = correct_predictions / total_samples\n",
    "        \n",
    "        return average_loss, average_accuracy\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        self.history = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "        \n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val = self.scaler.transform(X_val)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            train_loss, train_accuracy = self._run_single_epoch(X_train, y_train, optimize=True)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_accuracy'].append(train_accuracy)\n",
    "            \n",
    "            val_loss, val_accuracy = self._run_single_epoch(X_val, y_val, optimize=False)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_accuracy'].append(val_accuracy)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch + 1}: '\n",
    "                      f'train_loss={train_loss} train_accuracy={train_accuracy} '\n",
    "                      f'val_loss={val_loss} val_accuracy={val_accuracy}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_correct_predictions(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Counts the number of correct predictions.\n",
    "\n",
    "        :param y_true: true labels\n",
    "        :param y_pred: predicted labels\n",
    "        :return: number of correct predictions\n",
    "        \"\"\"\n",
    "        return np.sum(y_true == y_pred.argmax(axis=-1))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Evaluates the network's performance on the provided data.\n",
    "\n",
    "        :param X: The input data\n",
    "        :return: class predictions\n",
    "        \"\"\"\n",
    "        X = self.scaler.transform(X)\n",
    "        y_pred = self.forward(X)\n",
    "        return y_pred.argmax(-1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8371157-c924-473f-9018-71f9708c1598",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4035d0-5598-4d55-8ae8-7fdb39cf7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Loads data and splits them to X and Y\n",
    "    '''\n",
    "    data = load_wine()\n",
    "    return data['data'], data['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ead64ff-d24e-43fc-b322-4215a77ef8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56eb67cf-07b1-449d-a3bc-d16032890dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, Y, model_args, n_splits=5):\n",
    "    model_args = model_args.copy()\n",
    "    optim = model_args.pop('optimizer').copy()\n",
    "    optim_name = optim.pop('name')\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=model_args.get('random_seed', 0))\n",
    "    acc = []\n",
    "    for i, (train_indices, val_indices) in enumerate(skf.split(X, Y)):\n",
    "        if optim_name == 'SGD':\n",
    "            opt = SGD(**optim)\n",
    "        elif optim_name == 'Adam':\n",
    "            opt = Adam(**optim)\n",
    "        elif optim_name == 'AdaGrad':\n",
    "            opt = AdaGrad(**optim)\n",
    "        else:\n",
    "            raise ValueError('wrong optimizer')\n",
    "            \n",
    "        model = NeuralNetwork(optimizer=opt, **model_args)\n",
    "        model.fit(X[train_indices], Y[train_indices], X[val_indices], Y[val_indices])\n",
    "        acc.append(model.history['val_accuracy'][-1])\n",
    "            \n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e89086b-6a19-40a2-86fb-26fb079aef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X, Y, iterations, reps, pool=__builtins__):\n",
    "    '''\n",
    "    performs a random search to find best hyperparameters for the model.\n",
    "    `iterations` different hyperparameters are randomized, and evaluated `reps` times (with different random seeds)\n",
    "    returns best hyperparameters and accuracy\n",
    "    '''\n",
    "    args = [\n",
    "        dict(hidden_sizes=[round(2 ** np.random.randint(0, 8)) for _ in range(np.random.randint(0, 4))],\n",
    "             batch_size=np.random.randint(1, 32),\n",
    "             num_epochs=np.random.randint(1, 100),\n",
    "             optimizer=np.random.choice([\n",
    "                 {\n",
    "                     'name': 'SGD',\n",
    "                     'learning_rate': 10 ** np.random.normal(-3, 0),\n",
    "                     'momentum': np.random.uniform(0, 0.99),\n",
    "                 },\n",
    "                 {\n",
    "                     'name': 'Adam',\n",
    "                     'learning_rate': 10 ** np.random.normal(-3, 0),\n",
    "                     'beta1': np.random.uniform(0, 0.99),\n",
    "                     'beta2': np.random.uniform(0, 0.99),\n",
    "                 },\n",
    "                 {\n",
    "                     'name': 'AdaGrad',\n",
    "                     'learning_rate': 10 ** np.random.normal(-3, 0),\n",
    "                 },\n",
    "             ])\n",
    "        ) for i in range(iterations)\n",
    "    ]\n",
    "    accs = np.array([\n",
    "        list(pool.map(partial(evaluate_model, X, Y), [a | {'random_seed': j} for a in args]))\n",
    "        for j in range(reps)\n",
    "    ])\n",
    "    accs = accs.mean(0)\n",
    "    i = accs.argmax()\n",
    "    return args[i], accs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8da81-918c-4691-a030-e5ee4dab5781",
   "metadata": {},
   "source": [
    "# Finding best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e45438ef-96bb-4844-b894-f7de5378c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADS = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ecf5400-09fa-44f1-839b-608fe0df03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 152 ms, total: 35.7 s\n",
      "Wall time: 35.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'hidden_sizes': [8, 8],\n",
       "  'batch_size': 15,\n",
       "  'num_epochs': 31,\n",
       "  'optimizer': {'name': 'SGD',\n",
       "   'learning_rate': 0.001,\n",
       "   'momentum': 0.9346139123602158}},\n",
       " 0.9888888888888888)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with Pool(4) as pool:\n",
    "    best_args, best_accuracy = random_search(X, Y, iterations=16, reps=2)\n",
    "best_args, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33132793-d2dd-46ce-b647-baaab6bef5bf",
   "metadata": {},
   "source": [
    "# Evaulate model on best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f92aaa7-c0ae-4bf8-9816-006af76eb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_and_plot(X, Y, best_args, verbose=True):\n",
    "    \"\"\"\n",
    "    Plots and evaluate model on best hyperparameters\n",
    "    \"\"\"\n",
    "    num_epochs = best_args['num_epochs']\n",
    "    hidden_sizes = best_args['hidden_sizes']\n",
    "    batch_size = best_args['batch_size']\n",
    "    optimizer_args = best_args['optimizer']\n",
    "    learning_rate = optimizer_args['learning_rate']\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    history = []\n",
    "    for i, (train_indices, val_indices) in enumerate(skf.split(X, Y)):\n",
    "        if optimizer_args['name'] == 'SGD':\n",
    "            optimizer = SGD(learning_rate=learning_rate, momentum=optimizer_args.get('momentum'))\n",
    "        elif optimizer_args['name'] == 'Adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_args.get('beta1'), beta2=optimizer_args.get('beta2'))\n",
    "        else: \n",
    "            optimizer = AdaGrad(learning_rate=learning_rate)\n",
    "\n",
    "        model = NeuralNetwork(optimizer=optimizer, num_epochs=num_epochs, hidden_sizes=hidden_sizes, batch_size=batch_size)\n",
    "        model.fit(X[train_indices], Y[train_indices], X[val_indices], Y[val_indices])\n",
    "        history.append(model.history)\n",
    "\n",
    "    history = {key: np.mean([h[key] for h in history], 0) for key in history[0].keys()}\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.lineplot(pd.DataFrame(history)[['train_accuracy', 'val_accuracy']])\n",
    "    plt.ylim(0, 1.05)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.lineplot(pd.DataFrame(history)[['train_loss', 'val_loss']])\n",
    "    plt.ylim(0, 1.05)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Evaluate model on best args : {best_args}\")\n",
    "        print(f\"train loss: {history['train_loss'][-1]}\")\n",
    "        print(f\"val_accuracy: {history['val_accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7013b34b-ab55-4b2d-8df2-dc41dd0e669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model on best args : {'hidden_sizes': [16], 'batch_size': 24, 'num_epochs': 45, 'optimizer': {'name': 'SGD', 'learning_rate': 0.001, 'momentum': 0.7201586822316817}}\n",
      "train loss: 0.024021990706166896\n",
      "val_accuracy: 0.9830158730158731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_and_plot(X, Y, best_args, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e576c-1d6d-4f3a-948f-4420ad735691",
   "metadata": {},
   "source": [
    "## Additional Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b0068fd-92ba-4c54-b871-5146189aabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_factor_dependency(name, values, default_args, reps=5, xlog=False, pool=__builtins__, show=True):\n",
    "\n",
    "    res = {name: [], 'accuracy': []}\n",
    "    for arg in values:\n",
    "        args = default_args.copy()\n",
    "        args[name] = arg\n",
    "        for accuracy in pool.map(partial(evaluate_model, X, Y, model_args), [args | {'random_seed': i} for i in range(reps)]):\n",
    "            if isinstance(arg, float):\n",
    "                res[name].append(arg)\n",
    "            else:\n",
    "                res[name].append(str(arg))\n",
    "            res['accuracy'].append(accuracy)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(res) \n",
    "    sns.lineplot(data=df, x=name, y='accuracy', errorbar='sd')\n",
    "    sns.scatterplot(data=df, x=name, y='accuracy', alpha=0.05)\n",
    "    if xlog:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    # best red line \n",
    "    aggregated_df = df.groupby(name).mean().reset_index()\n",
    "    row = aggregated_df[aggregated_df.accuracy == aggregated_df.accuracy.max()].iloc[0]\n",
    "    plt.axvline(row[name], linestyle='dashed', color='r')\n",
    "    plt.title(f'{name}\\nfound best {name}={row[name]} with average accuracy {row[\"accuracy\"] * 100:.2f}%')\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e70ca042-01a7-432f-883a-69c4f4dd48dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6430/253862261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTHREADS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplot_factor_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden_sizes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6430/3507119218.py\u001b[0m in \u001b[0;36mplot_factor_dependency\u001b[0;34m(name, values, default_args, reps, xlog, pool, show)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'random_seed'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_args' is not defined"
     ]
    }
   ],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('hidden_sizes', [[2 ** i] for i in range(0, 11)], best_args, reps=64, pool=pool, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cbc35-9f84-4958-8503-6ab11b5aebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('hidden_sizes', [[2 ** i] for i in range(0, 11)], best_args | {'learning_rate': 0.01}, reps=64, pool=pool, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c71f1-39f1-439b-944b-d5adb4d718a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('learning_rate', np.logspace(-4, 0, base=10, num=50), best_args, reps=64, pool=pool, xlog=True, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4e88e-9a5d-4b89-9f13-0b2c90eb6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('num_epochs', np.arange(1, 31), best_args, reps=64, pool=pool, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43de4e-1a55-4189-b08b-8fbd7620113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('batch_size', np.arange(1, 33), best_args, reps=64, pool=pool, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c1017-2d9a-4af6-8575-e7ae3530758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(THREADS) as pool:\n",
    "    plot_factor_dependency('batch_size', np.arange(1, 33), best_args | {'learning_rate': 0.02}, reps=64, pool=pool, show=False)\n",
    "    plt.axhline(best_accuracy, color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f7485-7619-4a06-912d-0c65cbb4d191",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28510eec-3998-45db-93f1-5704a89b2947",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NeuralNetwork.__init__() got an unexpected keyword argument 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6430/4208419381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: NeuralNetwork.__init__() got an unexpected keyword argument 'input_size'"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(input_size=X.shape[1], output_size=Y.max() + 1, **best_args)\n",
    "model.fit(X, Y)\n",
    "preds = model.predict(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, preds, normalize=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0168312-9acd-48bb-97b6-02c3b201cde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6430/3773630932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf34045-2aec-4e45-852b-9df86ef04411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
